{% extends 'base.html' %}
{% load static %}
{% block title %}Sentence Analysis{% endblock %}
{% block content %}


 <!-- Registration -->
 <div id="registration" class="form-1 bg-dark-blue">
    <div class="container">
        <div class="row">
            <div class="col-lg-6">
                <h1>About Us</h1>
                <p>
                    At the heart of our work lies a simple yet profound belief: the internet 
                    should be a space where everyone feels welcome. Our Toxic Comment Detection 
                    system is designed to combat online toxicity, empowering users to identify harmful 
                    language and fostering healthier digital interactions. We blend the latest advancements 
                    in natural language processing with a commitment to inclusivity and positivity.
                </p>
                <form method="post">
                    {% csrf_token %}
                    <div class="form-group">
                        <label for="exampleFormControlTextarea1" class="form-label">Enter Comment</label>
                        <textarea class="form-control" name="comment" id="exampleFormControlTextarea1" rows="3"></textarea>
                    </div>
                    <button type="submit" class="form-control-submit-button">Classify</button>
                </form>
                
            </div>

            <div class="col-lg-6">
                <div class="text-container text-light">
                    {% if result %}
                        
                        <h2>Sentence Analysis:</h2>
                        <p><strong>Comment:</strong> <em>"{{ analyzed_comment }}"</em></p>
                        
                        <table class="table">
                            <thead>
                              <tr>
                                <th scope="col"><p>Sentiment</p></th>
                                <th scope="col"><p>Confidence</p></th>
                                <th scope="col"><p>Interpretation</p></th>
                                <!-- <th scope="col">Recommended Action</th> -->
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td>
                                    <p>
                                        {% if result.0.label == 'toxic' %}
                                            <span class="badge badge-danger">Toxic</span>
                                        {% else %}
                                            <span class="badge badge-success">Non-Toxic</span>
                                        {% endif %}
                                    </p>
                                </td>
                                <td><p>{{ result.0.score|floatformat:2 }}%</p></td>
                                <td>
                                    <p>
                                        {% if result.0.label == 'toxic' %}
                                            The input comment contains language that may be harmful or offensive.
                                        {% else %}
                                            The input comment appears safe and non-offensive.
                                        {% endif %}
                                    </p>
                                </td>
                              </tr>
                            </tbody>
                        </table>
                    {% else %}
                    
                        <h2>
                            Sentence Analysis (Overview:)
                        </h2>
                        <p>
                            Sentence analysis evaluates the sentiment or toxicity of a full sentence rather than 
                            breaking it into individual words. It considers the context and relationships between 
                            words, which is critical for accurately identifying subtle nuances in language.
                        </p>
                        <ul class="list-unstyled li-space-lg">
                            <h5>How It Works:</h5>
                            <li class="media">
                                <i class="fas fa-square"></i><div class="media-body">
                                    The entire sentence is processed using natural language processing (NLP) techniques.
                                </div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i><div class="media-body">
                                    Sentiment analysis models, like transformers or RNNs, evaluate the sentence holistically.
                                </div>
                            </li>
                            <li class="media">
                                <i class="fas fa-square"></i><div class="media-body">
                                    The analysis considers word dependencies, context, and grammar to classify the overall tone or toxicity.
                                </div>
                            </li>
                        </ul>
                    {% endif %}
                    
                </div> <!-- end of text-container -->
            </div> <!-- end of col -->
            
        </div> <!-- end of row -->
    </div> <!-- end of container -->
</div> <!-- end of form-1 -->
<!-- end of registration -->
   

    
{% endblock %}